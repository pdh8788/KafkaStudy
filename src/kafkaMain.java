public class kafkaMain {

    /**
     * 1. 카프카의 구성
     *  - 카프카는 크게 프로듀서, 카프카(브로커), 컨슈머, 주키퍼로 구성되어 있다.
     *  1) 주키퍼
     *   주키퍼는 컨슈머와 통신하는 부분 외에도 카프카와 직접 통신을 하면서, 카프카의 메타데이터 정보를 주키퍼에 저장하고,
     *   카프카의 상태관리 등의 목적으로 주키퍼를 이용합니다. 이렇게 카프카는 주키퍼와 긴밀하게 통신을 하기 때문에
     *   주키퍼 사용이 필수 조건입니다.
     *
     *   최근 들어 하둡, 나이파이, 에이치베이스, 스톰 등 많은 애플리케이션이 부하 분산 및 확장이 용이한 분산 애플리케이션으로
     *   개발되고 있습니다. 하지만 이러한 분산 애플리케이션을 사용하게 되면, 분산 애플리케이션 관리를 위한
     *   안정적인 코디네이션 애플레키이션이 추가로 필요하게 됩니다.
     *
     *   분산 애플리케이션을 개발하면서 동시에 코디네이션 애플리케이션도 개발하다 보면, 코디네이션 애플리케이션을 위한
     *   추가적인 개발 리소스가 필요하게 되므로, 이미 안정적인 코디네이션 서비스로 검증된 주키퍼를 많이 사용하고 있습니다.
     *
     *   주키퍼는 분산 애플리케이션을 위한 코디네이션 시스템입니다. 분산 애플리케이션이 안정적인 서비스를 할 수 있도록
     *   분산되어 있는 각 애플리케이션의 정보를 중앙에 집중하고 구성 관리, 그룹 관리 네이밍, 동기화 등의 서비스를 제공합니다.
     *
     *   주키퍼는 서버 여러 대를 앙상블로 구성하고, 분산 애플리케이션들이 각각 클라이언트가 되어 주키퍼 서버들과 커넥션을 맺은 후 상태 정보등을
     *   주고받게 됩니다. 상태 정보들은 주키퍼의 지노드라 불리는 곳에 키 값 형태로 저장하고, 지노드에 키 값이 저장된 것을 이용하여
     *   분산 애플리케이션들은 서로 데이터를 주고받게 됩니다.
     *
     *  지노드는 우리가 알고 있는 일반적인 디렉토리와 비슷한 형태로서 자식 노드를 가지고 있는 계층형 구조로 구성되어 있습니다.
     *  주키퍼의 각 지노드는 데이터 변경 등에 대한 유효성 검사 등을 위해 버전 번호를 관리하게 되며, 지노드의
     *  데이터가 변경될 때마다 지노드의 버전 번호가 증가합니다.
     *
     *  저장용으로 설계된 일반적인 파일시스템과 달리 주키퍼에 저장되는 데이터는 모두 메모리에 저장되어 처리량이 매우 크고
     *  속도 또한 매우 빠릅니다. 또한 주키퍼는 좀 더 신뢰성 있는 서비스를 위해 앙상블이라는 호스트 세트를 구성할 수 있습니다.
     *  앙상블로 구성되어 있는 주키퍼는 과반수 방식에 따라 살아 있는 노드 수가 과반수 이상 유지된다면 지속적인 서비스가 가능합니다.
     *
     *  1-1) 주키퍼 환경설정
     *  tickTime = 2000 // 주키퍼가 사용하는 시간에 대한 기본 측정 단위 (밀리초)
     *  initLimit = 10 // 팔로워가 리더와 초기에 연결하는 시간에 대한 타임 아웃 tick의 수
     *  syncLimit = 5 // synclimit: 팔로워가 리더와 동기화 하는 시간에 대한 타임아웃 tick의 수
     *  dataDir = /data // 주키퍼의 트랜잭션 로그와 스냅샷이 저장되는 데이터 저장 경룁니다.
     *  clientPort: 주키퍼 사용 TCP 포트
     *  server.x : 주키퍼 앙상블 구성을 위한 서버 설정이며, server.myid 형식으로 사용합니다.
     *
     *  1-2) 카프카 설치 및 환경설정
     *  클러스터 구성을 할 수 있는 분산 애플리케이션의 한 종류인 카프카는 클러스터를 구성하는 서버 대수를 정해야 합니다.
     *  다만, 분산 애플리케이션이라는 면에서 보면 주키퍼와 동일하지만 운영되는 방식입낟.
     *  과반수 방식으로 운영되어 홀수로 서버를 구성해야 하는 카프카 클러스터는 홀수 운영 서버를 하지 않아도 됩니다.
     *
     *  broker.id=1 // 브로커 아이디 설정
     *  log.dirs=/data1, /data2 // 물리적 디스크를 여러 사용하는 경우를 위해 /data1, /data2의 2개로 준비
     *  zookeeper.connect = peter-zk001:2181, peter-zk002:2181, peter-zk003:2181/peter-kafka
     *
     *  delete.topic.enable : 토픽 삭제 기능 on/off
     *  default.replication.factor : 리플리케이션 팩터 옵션을 주지 않았을 경우의 기본값
     *  min.insync.replicas : 최소 리플리케이션 팩터
     *  auto.create.topics.enable : 존재하지 않은 토픽으로 퍼블리셔가 메시지를 보냈을 때 자동으로 토픽 생성
     *  ... 88page
     *
     *  2. 카프카 상태 확인
     *  2-1) TCP 포트 확인
     *  주키퍼의 기본 TCP 포트는 2181이고, 카프카의 기본 TCP 포트는 9092입니다.
     *  포트가 리스닝 상태라는 의미는 애플리케이션이 TCP를 사용하는 서버에서 실행중이고 다른 컴퓨터와 연결될 때까지 기다린다는 것으로서,
     *  다른 말로는 수신 대기입니다.
     *  -- netstat -ntlp | grep 2181 -> 상태값 LISTEN 확인
     *
     *  2-2) 카프카 로그 확인
     *  -- cat /usr/local/kafka/logs/server.log
     *
     *  3. 카프카 디자인
     *  3-1) 분산 시스템
     *  장점 : 1) 단일 시스템보다 더 높은 성능
     *        2) 분산 시스템 중 하나의 서버 또는 노드 등이 장애가 발생하면 다른 서버 또는 노드가 처리 가능
     *        3) 시스템 확장 용이
     *        
     *
     *  3-2) 페이지 캐시
     *  카프카는 처리량을 높이기 위한 기능을 몇 가지 추가 했고 그 기능 중 하나가 페이지 캐시를 이용하는 것입니다.
     *  OS는 물리적 메모리에 애플리케이션이 사용하는 부분을 할당하고 남은 잔여 메모리 일부를 페이지 캐시로 유지해
     *  OS의 전체적인 성능 향상을 높이게 됩니다. 이렇게 잔여 메모리를 이용해 디스크에 읽고 쓰기를 하지 않고 페이지 캐시를 통해
     *  읽고 쓰는 방식을 사용하면 처리 속도가 매우 빠르기 때문에 전체적인 성능을 향상 시킬 수 있습니다.
     *
     *  카프카는 초당 메시지 단위, 메가비트 단위를 처리함에 있어 5GB의 힙 메모리면 충분하다고 남아 있는 메모리는 페이지 캐시로
     *  사용하기를 권장합니다.
     *
     *  3-3) 배치 전송 처리
     *  카프카에서는 작은 I/O를 묶어서 처리할 수 있도록 배치 작업으로 처리합니다.
     *
     *  3.2 카프카 데이터 모델
     *  3.2.1 토픽의 이해
     *  카프카는 클러스터 토픽이라 불리는 곳에 데이터를 저장합니다.
     *
     *  3.2.2 파티션의 이해
     *  카프카에서 효율적인 메시지 전송과 속도를 높이려면 토픽의 파티션 수를 늘려 줘야 합니다.
     *  토픽에 대해 파티션 수를 4개로 늘리면, 파티션 수와 동일하게 프로듀서 수도 4개로 늘리면 됩니다.
     *  이처럼 병렬 처리 방식으로 동시에 뉴스 토픽으로 메시지를 보낼수 있게 되어 4개의 메시지를 보내는데는 모두 1초가 소요 됩니다.
     *
     *  빠른 전송을 위해서는 파티션을 늘려야 하며, 그 수만큼 프로듀서 수도 늘려야 제대로 된 효과를 볼 수 있습니다.
     *
     *  *** 파티션 수를 무조건 늘려야 할까?
     *  파티션 수가 증감하에 따라 빠른 전송이 가능하다는 사실을 알게 되었습니다. 그렇다면 토픽의 파티션 수를 무조건 많이 늘려줘야 할까요?
     *  파티션 수를 늘리면 생기는 단점
     *
     *  1) 파일 핸들러의 낭비
     *  각 파티션은 브로커의 디렉토리와 매핑되고, 저장되는 데이터마다 2개의 파일이 있습니다. 카프카에서는 모든 디렉토리의 파일들에
     *  대해 파일 핸들을 열게 됩니다. 결국 파티션의 수가 많을수록 파일 핸들 수 역시 많아지게 되어 리소스를 낭비하게 됩니다.
     *
     *  2) 장애 복구 시간 증가
     *  카프카는 높은 가용성을 위해 리플리케이션을 지원합니다. 브로커에는 토픽이 있고, 토픽은 여러 개의 파티션으로 나뉘어 있으므로,
     *  브로커에는 여러 개의 파티션이 존재합니다. 또한, 각 파티션마다 리플리케이션이 동작하게 되며, 하나는 파티션의 리더이고
     *  나머지는 파티션의 팔로워가 됩니다.
     *  만약 브로커가 다운되면 해당 브로커에 리더가 있는 파티션은 일시적으로 사용할 수 없게 되므로, 카프카는 리더를 팔로워 중 하나로 이동시켜
     *  클라이언트 요청을 처리할 수 있게 됩니다. 이와 같은 장애처리는 컨트롤러로 지정된 브로커가 수행합니다. 만약 컨트롤러 역할을 수행하는
     *  브로커가 다운되면 살아 있는 브로커 중 하나가 자동으로 컨트롤러 역할을 대신 수행합니다.
     *
     *  이렇게 파티션의 수가 많아지면 장애 발생시 복구 시간이 길어지게 됩니다.
     *
     *
     * 3.2.3 토픽의 적절한 파티션 수
     * 토픽의 파티션 수를 정할 때는 목표 처리량의 기준을 잡아야 합니다. 프로듀서 입장에서 4개의 프로듀서를 통해 각각 초당 10개의 메시지를 카프카의
     * 토픽으로 보낸다고 하면, 카프카의 토픽에서 초당 40개의 메시지를 받아줘야 합니다. 만약 해당 토픽에서 파티션을 1로 했을 때
     * 초당 10개의 메시지만 받아준다면 파티션을 4로 늘려서 목표 처리량을 처리할 수 있도록 변경합니다.
     *             서버 수             서버당 메시지 전송 수        합계          필요 파티션 수
     * 프로듀서         4                  10메시지/초         10메시지/초          4
     * 컨슈머          8                   5메시지/초          40메시지/초         8
     *
     * 카프카에서 파티션 수의 증가는 필요할 경우 아무떄나 변경이 가능하지만, 반대로 파티션의 수를 줄이는 방법은 제공하지 않습니다.
     *
     * 3.2.3 오프셋과 메시지 순서
     * 카프카에서는 각 파티션마다 메시지가 저장되는 위치를 오프셋이라고 부르고, 오프셋은 파티션 내에서 유일하고 순차적으로 증가하는
     * 숫자의 형태로 되어 있습니다.
     *
     * 3.3 카프카의 고가용성과 리플리케이션
     * 카프카는 분산 애플리케이션으로 서버의 물리적 장애가 발생하는 경우에도 높은 가용성으 보장합니다.
     * 이를 위해 카프카는 리플리케이션 기능을 제공합니다. 카프카의 리플리케이션은 토픽 자체를 리플리케이션하는 것이 아니라,
     * 토픽을 이루는 각각의 파티션을 리플리케이션 하는 것입니다.
     *
     * 3.3.1 리플리케이션 팩터와 리더, 팔로워의 역할
     *  설정 파일에서 default.replication.factor 항목을 찾은 뒤 2 또는 3등 원하는 숫자로 변경하면 됩니다.
     *
     *  카프카의 리플리케이션은 토픽이 아니라, 토픽을 이루는 각각의 파티션을 리플리케이션하는 것입니다.
     *  리플리케이션으로 설정하게 되면 각각의 토픽(파티션)은 리더와 팔로워로 복제 됩니다.
     *  리더와 팔로워는 각자 역활이 나뉘어 있는데 가장 중요한 핵심은 모든 읽기와 쓰기가 리더를 통해서만 일어난다는 점입니다.
     *
     *  3.3.2 리더와 팔로워의 관리
     *   리더는 모든 데이터의 읽기 쓰기에 대한 요청에 응답하면서 데이터를 저장해 나가고, 팔로워는 리더를 주기적으로 보면서 자신에게 없는 데이터를
     *   리더로부터 주기적으로 가져오는 방법으로 리플리케이션을 유지합니다. 리더와 팔로워 모두 주어진 역할에 맞게 잘 동작하고 있다면
     *   전혀 문제가 없지만 팔로워에 문제가 있어 리더로부터 데이터를 가져오지 못하면 정합성이 맞지 않게 됩니다.
     *   리더가 다운되는 경우 팔로워가 새로운 리더로 승격 되어야 하는데, 데이터가 일치하지 않으므로 큰 문제가 발생할 수 있습니다.
     *
     *   카프카에서는 이러한 현상을 방지하고자 ISR(IN SYNC REPLICA)라는 개념을 도입했습니다.
     *
     *   ISR이라는 것은 한마디로 표현하자면 현재 리플리케이션이 되고 있는 리플리케이션 그룹입니다. ISR에 속해 있는 구성원만이
     *   리더의 자격을 가질 수 있습니다. 카프카에서는 리더가 다운될 경우팔로워가 그 역할을 대신해야 하기 때문에
     *   리더와 데이터 동기화 작업을 매우 중요하게 처리하고 있으며 이것을 유지하는 것이 바로 ISR입니다. 즉 ISR이라는 그룹을 만들어
     *   리플리케이션의 신뢰성을 높이고 있는 것입니다.
     *
     *   3.3.3 모든 카프카 클러스터가 다운 된다면
     *    카프카 클러스터가 모두 다운되는 최악의 상황이 발생한 경우 우리가 선택할 수 있는 방법은 2가지가 있습니다.
     *    1. 마지막 리더가 살아나기를 기다린다.
     *    2. ISR에서 추방되었지만 먼저 살아나면 자동으로 리더가 된다.
     *
     *    1번의 경우 "재시작시 마지막 리더가 반드시 시작되어야 한다." 라는 필수 조건이 필요합니다.
     *        -> 데이터의 정합성을 위해서.
     *
     *    2번의 경우 ISR에서 추방되었지만 먼저 살아나면 자동으로 리더가 되는 경우에는 마지막 리더가 아닌 클러스터 내에서 가장 먼저 살아나는
     *    리더 또는 팔로워가 새로운 리더가 됩니다. 하지만 마지막 리더가 아닌 ISR에서 추방당한 팔로워가 새로운 리더가 되면
     *    메시지 손실이 발생합니다. 메시지가 일부 손실이 되지만 클러스터 전체가 다운된 상황에서 브로커 하나만이라도 빠르게 정상화 되어
     *    서비스 역시 빠르게 정상화가 될 수 있습니다.
     *
     * 3.5 카프카에서 사용하는 주키퍼 지노드 역할
     *  주키퍼의 지노드는 주키퍼 CLI(command Line Interface)에 접근해 확인해 볼 수 있습니다.
     *   -- 주요 경로
     *   /peter-kafka/controller
     *    현재 카프카 클러스터의 컨트롤러 정보를 확인할 수 있습니다. 컨트롤러는 클러스터 내 브로커가 임의로 선정되고
     *    만약 컨트롤러인 브로커가 다운되면, 남아 있는 브로커 중 하나가 새로운 컨트롤러가 됩니다.
     *
     *   /peter-kafka/brokers
     *    브로커 관련된 정보들이 저장되며 카프카 설치할 때 브로커 컨피그에서 수정한 broker.id를 확인할 수 있습니다.
     *    브로커는 시작시 /brokers/ids에 broker.id로 지노드를 작성해 자신을 등록합니다. 만약 이미 사용 중인 broker.id를 등록하려고 시도하면
     *    오류가 발생합니다.
     *
     *    /pter-kafka/consumers
     *     컨슈머 관련된 정보들이 저장되며, 컨슈머가 각각의 파티션들에 대해 어디까지 읽었는지를 기록하는 오프셋 정보가 이곳에 저장됩니다.
     *     오프셋 정보는 지워지면 안되기 때문에 오프셋 관련 정보들은 주키퍼의 영구 노드로 저장됩니다.
     *     카프카 0.9버전 부터는 컨슈머 오프셋 저장 장소를 주키퍼 또는 카프카의 토픽을 선택할 수 있도록 제공하고 있지만,
     *     향후 카프카의 릴리스에서는 주키퍼에 오프셋을 저장하는 방법은 서비스가 종료될 예정입니다.
     *
     *     /peter-kafka/config
     *      토픽의 상세 설정 정보를 확인할 수 있습니다.
     *
     */


    public static void main(String[] args) {

    }

}
